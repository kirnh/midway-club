<!doctype html><html class="not-ready lg:text-base" style=--bg:#faf8f1 lang=en-us dir=ltr><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Building a Real-Time Audio Visualizer in SwiftUI-Midway</title>
<meta name=theme-color><meta name=description content="A step-by-step guide to creating a radial audio visualizer that responds to microphone input
Introduction
In this tutorial, we&rsquo;ll build &ldquo;AudioWave&rdquo; - a SwiftUI app that creates a beautiful radial visualization of audio captured from the device&rsquo;s microphone. This project demonstrates several important iOS development concepts:

Working with microphone permissions and audio recording
Processing real-time audio data
Creating custom visualizations with SwiftUI
Handling iOS permissions properly

Let&rsquo;s dive in and see how we can bring audio to life visually!"><meta name=author content="Midway"><link rel="preload stylesheet" as=style href=https://www.midway.club/main.min.css><link rel=preload as=image href=https://www.midway.club/theme.png><script defer src=https://www.midway.club/highlight.min.js onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://www.midway.club/favicon.ico><link rel=apple-touch-icon href=https://www.midway.club/apple-touch-icon.png><meta name=generator content="Hugo 0.145.0"><meta itemprop=name content="Building a Real-Time Audio Visualizer in SwiftUI"><meta itemprop=description content="A step-by-step guide to creating a radial audio visualizer that responds to microphone input
Introduction In this tutorial, we’ll build “AudioWave” - a SwiftUI app that creates a beautiful radial visualization of audio captured from the device’s microphone. This project demonstrates several important iOS development concepts:
Working with microphone permissions and audio recording Processing real-time audio data Creating custom visualizations with SwiftUI Handling iOS permissions properly Let’s dive in and see how we can bring audio to life visually!"><meta itemprop=datePublished content="2025-03-16T00:00:00+00:00"><meta itemprop=dateModified content="2025-03-16T00:00:00+00:00"><meta itemprop=wordCount content="1069"><meta property="og:url" content="https://www.midway.club/posts/ipad-audio-visualization/"><meta property="og:site_name" content="Midway"><meta property="og:title" content="Building a Real-Time Audio Visualizer in SwiftUI"><meta property="og:description" content="A step-by-step guide to creating a radial audio visualizer that responds to microphone input
Introduction In this tutorial, we’ll build “AudioWave” - a SwiftUI app that creates a beautiful radial visualization of audio captured from the device’s microphone. This project demonstrates several important iOS development concepts:
Working with microphone permissions and audio recording Processing real-time audio data Creating custom visualizations with SwiftUI Handling iOS permissions properly Let’s dive in and see how we can bring audio to life visually!"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-03-16T00:00:00+00:00"><meta property="article:modified_time" content="2025-03-16T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Building a Real-Time Audio Visualizer in SwiftUI"><meta name=twitter:description content="A step-by-step guide to creating a radial audio visualizer that responds to microphone input
Introduction In this tutorial, we’ll build “AudioWave” - a SwiftUI app that creates a beautiful radial visualization of audio captured from the device’s microphone. This project demonstrates several important iOS development concepts:
Working with microphone permissions and audio recording Processing real-time audio data Creating custom visualizations with SwiftUI Handling iOS permissions properly Let’s dive in and see how we can bring audio to life visually!"><link rel=canonical href=https://www.midway.club/posts/ipad-audio-visualization/></head><body class="bg-(--bg) text-black antialiased duration-200 ease-out [-webkit-tap-highlight-color:transparent] dark:text-white"><header class="mx-auto flex h-[4.5rem] max-w-(--w) px-8 whitespace-nowrap lg:justify-center"><div class="relative z-50 flex items-center ltr:mr-auto rtl:ml-auto"><a class="-translate-y-[1px] text-2xl font-medium" href=https://www.midway.club/>Midway</a><div class="btn-dark text-[0px] ltr:ml-4 rtl:mr-4 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.png)_left_center/_auto_theme('spacing.6')_no-repeat] [transition:_background-position_0.4s_steps(5)] dark:[background-position:right]" role=button aria-label=Dark></div></div><div class="btn-menu relative z-50 flex h-[4.5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden ltr:-mr-8 rtl:-ml-8" role=button aria-label=Menu></div><script>const htmlClass=document.documentElement.classList;setTimeout(()=>{htmlClass.remove("not-ready")},10);const btnMenu=document.querySelector(".btn-menu");btnMenu.addEventListener("click",()=>{htmlClass.toggle("open")});const metaTheme=document.querySelector('meta[name="theme-color"]'),lightBg="#faf8f1".replace(/"/g,""),setDark=e=>{metaTheme.setAttribute("content",e?"#000":lightBg),htmlClass[e?"add":"remove"]("dark"),localStorage.setItem("dark",e)},darkScheme=window.matchMedia("(prefers-color-scheme: dark)");if(htmlClass.contains("dark"))setDark(!0);else{const e=localStorage.getItem("dark");setDark(e?e==="true":darkScheme.matches)}darkScheme.addEventListener("change",e=>{setDark(e.matches)});const btnDark=document.querySelector(".btn-dark");btnDark.addEventListener("click",()=>{setDark(localStorage.getItem("dark")!=="true")})</script><div class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full flex-col justify-center bg-(--bg) pb-16 duration-200 select-none lg:static lg:h-auto lg:flex-row lg:bg-transparent! lg:pb-0 lg:transition-none"><nav class="lg:ml-12 lg:flex lg:flex-row lg:items-center lg:space-x-10 rtl:space-x-reverse"><a class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal" href=/posts/>Blogs</a><a class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal" href=/about/>About</a></nav></div></header><main class="prose prose-neutral dark:prose-invert relative mx-auto min-h-[calc(100vh-9rem)] max-w-(--w) px-8 pt-14 pb-16"><article><header class=mb-14><h1 class="my-0! pb-2.5">Building a Real-Time Audio Visualizer in SwiftUI</h1><div class="text-xs antialiased opacity-60"><time>Mar 16, 2025</time></div></header><section><p><em>A step-by-step guide to creating a radial audio visualizer that responds to microphone input</em></p><h2 id=introduction>Introduction</h2><p>In this tutorial, we&rsquo;ll build &ldquo;AudioWave&rdquo; - a SwiftUI app that creates a beautiful radial visualization of audio captured from the device&rsquo;s microphone. This project demonstrates several important iOS development concepts:</p><ul><li>Working with microphone permissions and audio recording</li><li>Processing real-time audio data</li><li>Creating custom visualizations with SwiftUI</li><li>Handling iOS permissions properly</li></ul><p>Let&rsquo;s dive in and see how we can bring audio to life visually!</p><h2 id=project-setup>Project Setup</h2><p>First, create a new SwiftUI project in Xcode:</p><ol><li>Open Xcode and select &ldquo;Create a new Xcode project&rdquo;</li><li>Choose &ldquo;App&rdquo; as the template</li><li>Name your project &ldquo;AudioWave&rdquo;</li><li>Select &ldquo;SwiftUI&rdquo; for the interface and &ldquo;Swift&rdquo; for the language</li><li>Choose a location to save your project</li></ol><h2 id=step-1-setting-up-microphone-permissions>Step 1: Setting Up Microphone Permissions</h2><p>iOS requires explicit permission to access the microphone. We need to:</p><ol><li>Add a usage description to our Info.plist</li><li>Request permission at runtime</li></ol><p>Create or modify your Info.plist file to include:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-xml data-lang=xml><span style=display:flex><span><span style=color:#75715e>&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;</span>
</span></span><span style=display:flex><span><span style=color:#75715e>&lt;!DOCTYPE plist PUBLIC &#34;-//Apple//DTD PLIST 1.0//EN&#34; &#34;http://www.apple.com/DTDs/PropertyList-1.0.dtd&#34;&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&lt;plist</span> <span style=color:#a6e22e>version=</span><span style=color:#e6db74>&#34;1.0&#34;</span><span style=color:#f92672>&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&lt;dict&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>&lt;key&gt;</span>NSMicrophoneUsageDescription<span style=color:#f92672>&lt;/key&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>&lt;string&gt;</span>AudioWave needs microphone access to visualize audio.<span style=color:#f92672>&lt;/string&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>&lt;key&gt;</span>CFBundleVersion<span style=color:#f92672>&lt;/key&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>&lt;string&gt;</span>1<span style=color:#f92672>&lt;/string&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>&lt;key&gt;</span>CFBundleShortVersionString<span style=color:#f92672>&lt;/key&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>&lt;string&gt;</span>1.0<span style=color:#f92672>&lt;/string&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>&lt;key&gt;</span>CFBundleIdentifier<span style=color:#f92672>&lt;/key&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>&lt;string&gt;</span>com.example.AudioWave<span style=color:#f92672>&lt;/string&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>&lt;key&gt;</span>CFBundleName<span style=color:#f92672>&lt;/key&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>&lt;string&gt;</span>AudioWave<span style=color:#f92672>&lt;/string&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>&lt;key&gt;</span>CFBundleExecutable<span style=color:#f92672>&lt;/key&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>&lt;string&gt;</span>$(EXECUTABLE_NAME)<span style=color:#f92672>&lt;/string&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>&lt;key&gt;</span>CFBundlePackageType<span style=color:#f92672>&lt;/key&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>&lt;string&gt;</span>APPL<span style=color:#f92672>&lt;/string&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&lt;/dict&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&lt;/plist&gt;</span>
</span></span></code></pre></div><p>The <code>NSMicrophoneUsageDescription</code> key is crucial - it provides the message shown to users when requesting microphone access.</p><h2 id=step-2-creating-the-audio-manager>Step 2: Creating the Audio Manager</h2><p>Next, we&rsquo;ll create an <code>AudioManager</code> class to handle microphone access and process audio data:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-swift data-lang=swift><span style=display:flex><span><span style=color:#75715e>// AudioManager.swift</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>import</span> <span style=color:#a6e22e>Foundation</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>import</span> <span style=color:#a6e22e>AVFoundation</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>import</span> <span style=color:#a6e22e>Accelerate</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>AudioManager</span>: ObservableObject {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>var</span> audioRecorder: AVAudioRecorder?
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>var</span> timer: Timer?
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    @Published <span style=color:#66d9ef>var</span> soundSamples: [CGFloat] = Array(repeating: <span style=color:#ae81ff>0.0</span>, count: <span style=color:#ae81ff>30</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>init</span>() {
</span></span><span style=display:flex><span>        setupAudioRecorder()
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>func</span> <span style=color:#a6e22e>setupAudioRecorder</span>() {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> audioSession = AVAudioSession.sharedInstance()
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>do</span> {
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>try</span> audioSession.setCategory(.playAndRecord, mode: .<span style=color:#66d9ef>default</span>)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>try</span> audioSession.setActive(<span style=color:#66d9ef>true</span>)
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>let</span> url = URL(fileURLWithPath: <span style=color:#e6db74>&#34;/dev/null&#34;</span>, isDirectory: <span style=color:#66d9ef>true</span>)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>let</span> recorderSettings: [String: Any] = [
</span></span><span style=display:flex><span>                AVFormatIDKey: Int(kAudioFormatAppleLossless),
</span></span><span style=display:flex><span>                AVSampleRateKey: <span style=color:#ae81ff>44100.0</span>,
</span></span><span style=display:flex><span>                AVNumberOfChannelsKey: <span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>                AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
</span></span><span style=display:flex><span>            ]
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            audioRecorder = <span style=color:#66d9ef>try</span> AVAudioRecorder(url: url, settings: recorderSettings)
</span></span><span style=display:flex><span>            audioRecorder?.isMeteringEnabled = <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>            audioRecorder?.record()
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            startMonitoring()
</span></span><span style=display:flex><span>        } <span style=color:#66d9ef>catch</span> {
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>&#34;AudioManager initialization failed: </span><span style=color:#e6db74>\(</span>error.localizedDescription<span style=color:#e6db74>)</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>func</span> <span style=color:#a6e22e>startMonitoring</span>() {
</span></span><span style=display:flex><span>        timer = Timer.scheduledTimer(withTimeInterval: <span style=color:#ae81ff>0.03</span>, repeats: <span style=color:#66d9ef>true</span>) { [<span style=color:#66d9ef>weak</span> <span style=color:#66d9ef>self</span>] <span style=color:#66d9ef>_</span> <span style=color:#66d9ef>in</span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>guard</span> <span style=color:#66d9ef>let</span> self = <span style=color:#66d9ef>self</span> <span style=color:#66d9ef>else</span> { <span style=color:#66d9ef>return</span> }
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>self</span>.audioRecorder?.updateMeters()
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e>// Get the power level from the recorder</span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>let</span> power = <span style=color:#66d9ef>self</span>.audioRecorder?.averagePower(forChannel: <span style=color:#ae81ff>0</span>) ?? <span style=color:#f92672>-</span><span style=color:#ae81ff>160</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e>// Convert to a 0-1 scale (dB is logarithmic, typically -160 to 0)</span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>let</span> normalizedPower = (power <span style=color:#f92672>+</span> <span style=color:#ae81ff>50</span>) <span style=color:#f92672>/</span> <span style=color:#ae81ff>50</span>
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e>// Add the new value and remove the oldest one</span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>self</span>.soundSamples.removeFirst()
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>self</span>.soundSamples.append(CGFloat(max(<span style=color:#ae81ff>0</span>, min(normalizedPower, <span style=color:#ae81ff>1</span>))))
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>func</span> <span style=color:#a6e22e>stopMonitoring</span>() {
</span></span><span style=display:flex><span>        timer?.invalidate()
</span></span><span style=display:flex><span>        timer = <span style=color:#66d9ef>nil</span>
</span></span><span style=display:flex><span>        audioRecorder?.stop()
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>deinit</span> {
</span></span><span style=display:flex><span>        stopMonitoring()
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>This class:</p><ul><li>Sets up an audio session and recorder</li><li>Creates a timer to regularly sample audio levels</li><li>Normalizes the audio power levels to a 0-1 scale</li><li>Maintains an array of recent samples for visualization</li><li>Provides methods to start and stop monitoring</li></ul><h2 id=step-3-building-the-radial-visualizer>Step 3: Building the Radial Visualizer</h2><p>Now, let&rsquo;s create a custom SwiftUI view to visualize our audio data:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-swift data-lang=swift><span style=display:flex><span><span style=color:#75715e>// RadialVisualizerView.swift</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>import</span> <span style=color:#a6e22e>SwiftUI</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>struct</span> <span style=color:#a6e22e>RadialVisualizerView</span>: View {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>var</span> samples: [CGFloat]
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>var</span> color: Color = .blue
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>var</span> body: some View {
</span></span><span style=display:flex><span>        GeometryReader { geometry <span style=color:#66d9ef>in</span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>let</span> size = min(geometry.size.width, geometry.size.height)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>let</span> middle = CGPoint(x: geometry.size.width <span style=color:#f92672>/</span> <span style=color:#ae81ff>2</span>, y: geometry.size.height <span style=color:#f92672>/</span> <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>let</span> radius = size <span style=color:#f92672>/</span> <span style=color:#ae81ff>2.5</span>
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            ZStack {
</span></span><span style=display:flex><span>                <span style=color:#75715e>// Background circle</span>
</span></span><span style=display:flex><span>                Circle()
</span></span><span style=display:flex><span>                    .fill(color.opacity(<span style=color:#ae81ff>0.1</span>))
</span></span><span style=display:flex><span>                    .frame(width: radius <span style=color:#f92672>*</span> <span style=color:#ae81ff>2</span>, height: radius <span style=color:#f92672>*</span> <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>                
</span></span><span style=display:flex><span>                <span style=color:#75715e>// Visualization bars</span>
</span></span><span style=display:flex><span>                ForEach(<span style=color:#ae81ff>0.</span>.&lt;samples.count, id: <span style=color:#960050;background-color:#1e0010>\</span>.<span style=color:#66d9ef>self</span>) { index <span style=color:#66d9ef>in</span>
</span></span><span style=display:flex><span>                    <span style=color:#66d9ef>let</span> angle = <span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> .pi <span style=color:#f92672>/</span> CGFloat(samples.count) <span style=color:#f92672>*</span> CGFloat(index)
</span></span><span style=display:flex><span>                    <span style=color:#66d9ef>let</span> barHeight = radius <span style=color:#f92672>*</span> samples[index] <span style=color:#f92672>*</span> <span style=color:#ae81ff>0.8</span>
</span></span><span style=display:flex><span>                    
</span></span><span style=display:flex><span>                    Rectangle()
</span></span><span style=display:flex><span>                        .fill(color)
</span></span><span style=display:flex><span>                        .frame(width: <span style=color:#ae81ff>3</span>, height: barHeight)
</span></span><span style=display:flex><span>                        .cornerRadius(<span style=color:#ae81ff>1.5</span>)
</span></span><span style=display:flex><span>                        .offset(y: <span style=color:#f92672>-</span>radius <span style=color:#f92672>-</span> barHeight <span style=color:#f92672>/</span> <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>                        .rotationEffect(.radians(Double(angle)))
</span></span><span style=display:flex><span>                }
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>            .position(middle)
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>#Preview {
</span></span><span style=display:flex><span>    RadialVisualizerView(samples: Array(repeating: CGFloat.random(<span style=color:#66d9ef>in</span>: <span style=color:#ae81ff>0.1</span>...<span style=color:#ae81ff>1.0</span>), count: <span style=color:#ae81ff>30</span>), color: .blue)
</span></span><span style=display:flex><span>        .frame(width: <span style=color:#ae81ff>300</span>, height: <span style=color:#ae81ff>300</span>)
</span></span><span style=display:flex><span>        .background(Color.black.opacity(<span style=color:#ae81ff>0.1</span>))
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>This view:</p><ul><li>Takes an array of audio samples and a color as input</li><li>Creates a circular background</li><li>Draws bars radiating outward from the center</li><li>Positions each bar at the correct angle</li><li>Sizes each bar based on the corresponding audio sample value</li></ul><h2 id=step-4-putting-it-all-together-in-contentview>Step 4: Putting It All Together in ContentView</h2><p>Finally, let&rsquo;s update our ContentView to integrate the AudioManager and RadialVisualizerView:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-swift data-lang=swift><span style=display:flex><span><span style=color:#75715e>// ContentView.swift</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>import</span> <span style=color:#a6e22e>SwiftUI</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>import</span> <span style=color:#a6e22e>AVFoundation</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>import</span> <span style=color:#a6e22e>AVFAudio</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>struct</span> <span style=color:#a6e22e>ContentView</span>: View {
</span></span><span style=display:flex><span>    @StateObject <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>var</span> audioManager = AudioManager()
</span></span><span style=display:flex><span>    @State <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>var</span> isRecording = <span style=color:#66d9ef>false</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>var</span> body: some View {
</span></span><span style=display:flex><span>        VStack {
</span></span><span style=display:flex><span>            Text(<span style=color:#e6db74>&#34;AudioWave&#34;</span>)
</span></span><span style=display:flex><span>                .font(.largeTitle)
</span></span><span style=display:flex><span>                .fontWeight(.bold)
</span></span><span style=display:flex><span>                .padding()
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            RadialVisualizerView(samples: audioManager.soundSamples, color: .blue)
</span></span><span style=display:flex><span>                .frame(height: <span style=color:#ae81ff>300</span>)
</span></span><span style=display:flex><span>                .padding()
</span></span><span style=display:flex><span>                .background(
</span></span><span style=display:flex><span>                    RoundedRectangle(cornerRadius: <span style=color:#ae81ff>16</span>)
</span></span><span style=display:flex><span>                        .fill(Color.black.opacity(<span style=color:#ae81ff>0.05</span>))
</span></span><span style=display:flex><span>                )
</span></span><span style=display:flex><span>                .padding()
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            Button(action: {
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>if</span> isRecording {
</span></span><span style=display:flex><span>                    audioManager.stopMonitoring()
</span></span><span style=display:flex><span>                } <span style=color:#66d9ef>else</span> {
</span></span><span style=display:flex><span>                    audioManager.setupAudioRecorder()
</span></span><span style=display:flex><span>                }
</span></span><span style=display:flex><span>                isRecording.toggle()
</span></span><span style=display:flex><span>            }) {
</span></span><span style=display:flex><span>                Text(isRecording ? <span style=color:#e6db74>&#34;Stop Listening&#34;</span> : <span style=color:#e6db74>&#34;Start Listening&#34;</span>)
</span></span><span style=display:flex><span>                    .padding()
</span></span><span style=display:flex><span>                    .background(isRecording ? Color.red : Color.blue)
</span></span><span style=display:flex><span>                    .foregroundColor(.white)
</span></span><span style=display:flex><span>                    .cornerRadius(<span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>            .padding()
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        .onAppear {
</span></span><span style=display:flex><span>            <span style=color:#75715e>// Request microphone permission when the view appears</span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> <span style=color:#75715e>#available</span>(<span style=color:#75715e>iOS</span> <span style=color:#ae81ff>17.0</span>, <span style=color:#f92672>*</span>) {
</span></span><span style=display:flex><span>                AVAudioApplication.requestRecordPermission(completionHandler: { granted <span style=color:#66d9ef>in</span>
</span></span><span style=display:flex><span>                    <span style=color:#66d9ef>if</span> granted {
</span></span><span style=display:flex><span>                        print(<span style=color:#e6db74>&#34;Microphone access granted&#34;</span>)
</span></span><span style=display:flex><span>                    } <span style=color:#66d9ef>else</span> {
</span></span><span style=display:flex><span>                        print(<span style=color:#e6db74>&#34;Microphone access denied&#34;</span>)
</span></span><span style=display:flex><span>                    }
</span></span><span style=display:flex><span>                })
</span></span><span style=display:flex><span>            } <span style=color:#66d9ef>else</span> {
</span></span><span style=display:flex><span>                <span style=color:#75715e>// Fallback for iOS versions before 17.0</span>
</span></span><span style=display:flex><span>                AVAudioSession.sharedInstance().requestRecordPermission { granted <span style=color:#66d9ef>in</span>
</span></span><span style=display:flex><span>                    <span style=color:#66d9ef>if</span> granted {
</span></span><span style=display:flex><span>                        print(<span style=color:#e6db74>&#34;Microphone access granted&#34;</span>)
</span></span><span style=display:flex><span>                    } <span style=color:#66d9ef>else</span> {
</span></span><span style=display:flex><span>                        print(<span style=color:#e6db74>&#34;Microphone access denied&#34;</span>)
</span></span><span style=display:flex><span>                    }
</span></span><span style=display:flex><span>                }
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>This view:</p><ul><li>Creates an instance of our AudioManager</li><li>Displays the app title</li><li>Shows the RadialVisualizerView with current audio samples</li><li>Provides a button to start/stop audio monitoring</li><li>Requests microphone permission when the view appears</li><li>Handles compatibility with different iOS versions</li></ul><h2 id=troubleshooting-common-issues>Troubleshooting Common Issues</h2><p>During development, we encountered several issues that you might also face:</p><h3 id=1-missing-avfoundation-import>1. Missing AVFoundation Import</h3><p>If you see an error like <code>Cannot find 'AVAudioSession' in scope</code>, make sure to import AVFoundation:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-swift data-lang=swift><span style=display:flex><span><span style=color:#66d9ef>import</span> <span style=color:#a6e22e>AVFoundation</span>
</span></span></code></pre></div><h3 id=2-multiple-infoplist-files>2. Multiple Info.plist Files</h3><p>If you get an error about multiple Info.plist files, you need to configure your project settings:</p><ol><li>Go to your project settings</li><li>Set <code>GENERATE_INFOPLIST_FILE = NO</code></li><li>Set <code>INFOPLIST_FILE = AudioWave/Info.plist</code></li></ol><h3 id=3-missing-required-infoplist-keys>3. Missing Required Info.plist Keys</h3><p>iOS requires certain keys in your Info.plist:</p><ul><li><code>CFBundleVersion</code> - The build number</li><li><code>CFBundleShortVersionString</code> - The version number</li><li><code>CFBundleIdentifier</code> - The bundle identifier</li><li><code>NSMicrophoneUsageDescription</code> - Explanation for microphone use</li></ul><h3 id=4-deprecated-api-methods>4. Deprecated API Methods</h3><p>For iOS 17+, use the updated microphone permission request method:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-swift data-lang=swift><span style=display:flex><span><span style=color:#66d9ef>if</span> <span style=color:#75715e>#available</span>(<span style=color:#75715e>iOS</span> <span style=color:#ae81ff>17.0</span>, <span style=color:#f92672>*</span>) {
</span></span><span style=display:flex><span>    AVAudioApplication.requestRecordPermission(completionHandler: { granted <span style=color:#66d9ef>in</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e>// Handle permission result</span>
</span></span><span style=display:flex><span>    })
</span></span><span style=display:flex><span>} <span style=color:#66d9ef>else</span> {
</span></span><span style=display:flex><span>    AVAudioSession.sharedInstance().requestRecordPermission { granted <span style=color:#66d9ef>in</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e>// Handle permission result</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h2 id=conclusion>Conclusion</h2><p>Congratulations! You&rsquo;ve built a real-time audio visualizer in SwiftUI. This project demonstrates:</p><ul><li>Working with device sensors (microphone)</li><li>Processing real-time data</li><li>Creating custom visualizations</li><li>Handling permissions properly</li><li>Supporting different iOS versions</li></ul><p>You can extend this project in many ways:</p><ul><li>Add different visualization styles</li><li>Allow users to customize colors and sensitivity</li><li>Save and share visualizations</li><li>Add audio effects or filters</li></ul><p>The combination of SwiftUI&rsquo;s powerful drawing capabilities with AVFoundation&rsquo;s audio processing makes it possible to create beautiful, responsive audio visualizations with relatively little code.</p><p>Happy coding!</p><hr></section><nav class="mt-24 flex overflow-hidden rounded-xl bg-black/[3%] text-lg leading-[1.2]! *:flex *:w-1/2 *:items-center *:p-5 *:font-medium *:no-underline dark:bg-white/[8%] [&>*:hover]:bg-black/[2%] dark:[&>*:hover]:bg-white/[3%]"><a class="ltr:pr-3 rtl:pl-3" href=https://www.midway.club/posts/what-is-midway/><span class="ltr:mr-1.5 rtl:ml-1.5">←</span><span>What is Midway?</span></a><a class="justify-end pl-3 ltr:ml-auto rtl:mr-auto" href=https://www.midway.club/posts/raspberrypi-ipad-bluetooth/><span>Persistent Bluetooth Connection Between Raspberry Pi and iPad</span><span class="ltr:ml-1.5 rtl:mr-1.5">→</span></a></nav></article></main><footer class="mx-auto flex h-[4.5rem] max-w-(--w) items-center px-8 text-xs tracking-wider uppercase opacity-60"><div class=mr-auto>&copy;2025<a class=link href=https://www.midway.club/>Midway</a></div><a class="link mx-6" href=https://gohugo.io/ rel=noopener target=_blank>powered by hugo️️</a>️
<a class=link href=https://github.com/nanxiaobei/hugo-paper rel=noopener target=_blank>hugo-paper</a></footer></body></html>